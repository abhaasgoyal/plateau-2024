- I found Section 2.1 a little confusing. It introduces capability terminology like "ambient authority" without any explanation. It introduces a case study that isn't used anywhere else in the paper. I might consider using one of your actual tasks as motivation instead.
- I was surprised that the study had three different tasks considering it only has four participants. My general preference is for small-N studies to have all the participants go through the same tasks --- that way you are eliminating at least one source of variation when interpreting the results.
- I was also surprised that participants completed the same task in both Wyvern and Rust, and always in that order. I would expect that implementing the task in one language would influence how a participant would implement the task in the other language. In general, I would encourage you to consider experimental designs that limit cross-condition effects.
- The designs of both Wyvern and the Rust cap-std library are quite important to understanding this study. I would consider explaining either in Section 2 or Section 4 how these technologies work, and how they differ in their approach to capabilities. 
- I think the example capability vulnerability for Network Pool in Rust (Section 5.2) is misleading. The cap-std threat model explicitly excludes untrusted Rust code: "cap-std is not a sandbox for untrusted Rust code. Among other things, untrusted Rust code could use unsafe or the unsandboxed APIs in std::fs" (source). One could have analyzed the difference between the Wyvern and cap-std threat models without needing a user study, so I would focus on the implications of participants' respective abilities to find (or not find) vulnerabilities within a given threat model
